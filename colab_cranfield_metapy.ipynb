{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab_cranfield_metapy.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "X7nGZYLzQ9-_",
        "G2xDn3TXQyhp",
        "yVZ88TGoRPlp"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codylw2/CourseProject/blob/main/colab_cranfield_metapy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7nGZYLzQ9-_"
      },
      "source": [
        "# Authenticate for Google Drive\r\n",
        "There is a file size limitation for my github repository so I have added the files that will be used for this notebook into my Google Drive and made them publicly shareable. In order to access them you must authenticate to Google. It should not matter what account you use to do this since the files are public."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ops1_efEHNH3"
      },
      "source": [
        "!pip install -q PyDrive\r\n",
        "!pip install -q metapy\r\n",
        "!pip install -q pytoml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hcb4Gx5iGtTL"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\r\n",
        "from pydrive.drive import GoogleDrive\r\n",
        "from google.colab import auth\r\n",
        "from oauth2client.client import GoogleCredentials\r\n",
        "auth.authenticate_user()\r\n",
        "gauth = GoogleAuth()\r\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\r\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2xDn3TXQyhp"
      },
      "source": [
        "# Acquire Files\r\n",
        "This section concerns itself with acquiring the files that are required to run the later scripts. It will also download a tuned version of the model so that there is no reason to run training unless desired. All of the scripts are stored within the git repo and that is the first thing download. The remaining supporting files are stored in my Google Drive account due to file size limitations on github. The files are publicly available so anyone should be able to download and use them. The Google Drive files are downloaded through the PyDrive python module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ2Lo1WO8Yqm"
      },
      "source": [
        "!git clone https://github.com/codylw2/CourseProject.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cTfIlnN8uSy"
      },
      "source": [
        "%cd /content/CourseProject/competition\r\n",
        "!mkdir json_data\r\n",
        "%cd json_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xw3CAf4Seog"
      },
      "source": [
        "The links shown below are what is generated by Google Driver when you get the link for a file. Contained within the link is an 'id' for the file/folder that you can use to download it.\r\n",
        "\r\n",
        "Initial source for how to download a file: https://buomsoo-kim.github.io/colab/2018/04/16/Importing-files-from-Google-Drive-in-Google-Colab.md/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwGJVqF0HD_Y"
      },
      "source": [
        "# test_docs.json https://drive.google.com/file/d/1XqHy17_eOGk-BE91AC3gmKyJ1PiEjc6A/view?usp=sharing\r\n",
        "downloaded = drive.CreateFile({'id':\"1XqHy17_eOGk-BE91AC3gmKyJ1PiEjc6A\"})\r\n",
        "downloaded.GetContentFile('test_queries.json')\r\n",
        "\r\n",
        "# train_docs.json : https://drive.google.com/file/d/1iyJ5F1BAT6BFKLOyumMt6z8jUaJ6KZLQ/view?usp=sharing\r\n",
        "downloaded = drive.CreateFile({'id':\"1XrBInztxbKW9FdNn8Tso9wPvnzkLbGaT\"})\r\n",
        "downloaded.GetContentFile('test_docs.json')\r\n",
        "\r\n",
        "# train_queries.json : https://drive.google.com/file/d/1Dp2ExBJtUBE3UOpSuh1AwQnCH6vbYnaD/view?usp=sharing\r\n",
        "downloaded = drive.CreateFile({'id':\"1Dp2ExBJtUBE3UOpSuh1AwQnCH6vbYnaD\"})\r\n",
        "downloaded.GetContentFile('train_queries.json')\r\n",
        "\r\n",
        "# train_qrels.json : https://drive.google.com/file/d/1tyGyuYtbGJHcKQIYoF4yaYCL9HRF2hku/view?usp=sharing\r\n",
        "downloaded = drive.CreateFile({'id':\"1tyGyuYtbGJHcKQIYoF4yaYCL9HRF2hku\"})\r\n",
        "downloaded.GetContentFile('train_qrels.json')\r\n",
        "\r\n",
        "# test_docs.json https://drive.google.com/file/d/1XrBInztxbKW9FdNn8Tso9wPvnzkLbGaT/view?usp=sharing\r\n",
        "downloaded = drive.CreateFile({'id':\"1iyJ5F1BAT6BFKLOyumMt6z8jUaJ6KZLQ\"})\r\n",
        "downloaded.GetContentFile('train_docs.json')\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiF0lFz-lmi1"
      },
      "source": [
        "We are deleting the current predictions file so that you can be absolutely sure it is getting creeated with the appropriate values. Don't worry if it says no such file or directory, that is expected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg3Arz3Bltvg"
      },
      "source": [
        "!rm -f /content/CourseProject/competition/predictions.txt\r\n",
        "!cat /content/CourseProject/competition/predictions.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVZ88TGoRPlp"
      },
      "source": [
        "# Create Cranfield Datasets\r\n",
        "This section creates the datasets in the standard Cranfield format so the metapy can use a ranker to rank the documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pfLT6i1LSSW"
      },
      "source": [
        "%cd /content/CourseProject/competition/cranfield_metapy\r\n",
        "\r\n",
        "WORKDIR = !pwd\r\n",
        "WORKDIR = WORKDIR[0]\r\n",
        "BASE = WORKDIR + \"/../..\"\r\n",
        "DATASET_DIR = BASE + \"/competition/datasets\"\r\n",
        "JSON_DIR = BASE + \"/competition/json_data\"\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUykgaR5bW5j"
      },
      "source": [
        "The next code block runs the script that generates the datasets from the json files that contain the queries, documents, and query relevance judgements, if training. The api is documented within the project documentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P69YeUGlMPEJ"
      },
      "source": [
        "!python $WORKDIR/create_cranfield.py \\\r\n",
        "    --run_type \"train;test\" \\\r\n",
        "    --query_keys \"query;question;narrative\" \\\r\n",
        "    --doc_keys \"title:abstract:intro\" \\\r\n",
        "    --cranfield_dir $WORKDIR \\\r\n",
        "    --input_dir $JSON_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5BKHVbeRUwV"
      },
      "source": [
        "# Generate Predictions\r\n",
        "This section uses a ranker to predict the relevance scores of documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zjeici_b-Er"
      },
      "source": [
        "The next code block is the most important code block within the notebook. It runs the script that generates the predictions for document relevance. It uses the ranker defined by the 'ranker' argument to rank the documents. The 'run_type' argument combined with the 'dat_keys' argument defines what dataset will be used to rank documents. If using multiple datasets you can define a weight for each dataset for when the predictions are combined into a single ranking."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6EhoeAcOrO-"
      },
      "source": [
        "!python $WORKDIR/search_eval.py \\\r\n",
        "    --run_type \"test\" \\\r\n",
        "    --ranker \"bm25\" \\\r\n",
        "    --params \"2.0;0.75;4450\" \\\r\n",
        "    --dat_keys \"title\" \\\r\n",
        "    --doc_weights \"1.0\" \\\r\n",
        "    --cranfield_dir $WORKDIR \\\r\n",
        "    --predict_dir $BASE \\\r\n",
        "    --remove_idx\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3Lu4aEqVrk3"
      },
      "source": [
        "This final code block outputs the predictions file that was generated with the predictions script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy4PF_MAQVjJ"
      },
      "source": [
        "!cat $BASE/predictions.txt"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}